{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from diffmask.models.sentiment_classification_sst import (\n",
    "    BertSentimentClassificationSST,\n",
    "    MyDataset,\n",
    "    my_collate_fn_token,\n",
    "    load_sst\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--gpu\", type=str, default=\"0\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0)\n",
    "    parser.add_argument(\n",
    "        \"--val_filename\",\n",
    "        type=str,\n",
    "        default=\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val_rationale\",\n",
    "        type=str,\n",
    "        default=\"\"\n",
    "   )\n",
    "    parser.add_argument(\n",
    "        \"--model_path\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "\n",
    "    )\n",
    "    \n",
    "    hparams, _ = parser.parse_known_args()\n",
    "    \n",
    "    torch.manual_seed(hparams.seed)\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = hparams.gpu\n",
    "    \n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = BertSentimentClassificationSST.load_from_checkpoint(hparams.model_path).to(device)\n",
    "\n",
    "model.freeze()\n",
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset, _ = load_sst(\n",
    "                hparams.val_filename, None, model.hparams.dataset, 3, hparams.val_rationale, model.hparams.token_cls\n",
    "            )\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=model.hparams.batch_size, collate_fn=my_collate_fn_token, num_workers=8\n",
    "        )\n",
    "\n",
    "my_name = ''\n",
    "dir_path = ''\n",
    "\n",
    "with open(dir_path + 'rationale_token_' + my_name + \".txt\", 'w') as f, \\\n",
    "        open(dir_path + \"rationale_idx_\" + my_name + \".txt\", 'w') as w:\n",
    "    for i, batch in tqdm(enumerate(val_dataloader), total=len(val_dataset) // model.hparams.batch_size):\n",
    "#     for i, batch in tqdm(enumerate(model.val_dataloader()), total=len(model.val_dataset) // model.hparams.batch_size):\n",
    "        inputs = model.tokenizer.batch_encode_plus(batch[0], pad_to_max_length=True, return_tensors='pt').to(device)\n",
    "        input_ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "        logits = model.forward(input_ids, mask, token_type_ids)[0]\n",
    "        results = logits.argmax(-1)\n",
    "        \n",
    "        for idx in range(len(batch[0])): \n",
    "            source_1 = model.tokenizer.tokenize(batch[0][idx][0])\n",
    "            source_2 = model.tokenizer.tokenize(batch[0][idx][1])\n",
    "            tokens = [\"[CLS]\"] + source_1 + [\"[SEP]\"] + source_2 + [\"[SEP]\"]\n",
    "            rationale, rationale_idx = [], []\n",
    "            \n",
    "            for j in range(mask[idx].sum()):\n",
    "                if j == (len(source_1) + 2):\n",
    "                    rationale.append('|')\n",
    "                else:\n",
    "                    if results[idx][j] == 1:\n",
    "                        rationale.append(tokens[j])\n",
    "                rationale_idx.append(str(int(results[idx][j])))\n",
    "\n",
    "            f.write(' '.join(rationale) + '\\n')\n",
    "            w.write(' '.join(rationale_idx) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from diffmask.models.sentiment_classification_sst import (\n",
    "    BertSentimentClassificationSST,\n",
    "    MyDataset,\n",
    "    my_collate_fn,\n",
    "    my_collate_fn_rationale,\n",
    "    load_sst\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--gpu\", type=str, default=\"0\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0)\n",
    "    parser.add_argument(\n",
    "        \"--val_filename\",\n",
    "        type=str,\n",
    "        default=\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val_rationale\",\n",
    "        type=str,\n",
    "        default=\"\"\n",
    "   )\n",
    "    parser.add_argument(\n",
    "        \"--model_path\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "    )\n",
    "\n",
    "    hparams, _ = parser.parse_known_args()\n",
    "    \n",
    "    torch.manual_seed(hparams.seed)\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = hparams.gpu\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = BertSentimentClassificationSST.load_from_checkpoint(hparams.model_path).to(device)\n",
    "\n",
    "model.freeze()\n",
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset, _ = load_sst(\n",
    "                hparams.val_filename, None, model.hparams.dataset, model.hparams.num_labels, hparams.val_rationale, model.hparams.token_cls\n",
    "            )\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=model.hparams.batch_size, collate_fn=my_collate_fn_rationale, num_workers=8\n",
    "        )\n",
    "\n",
    "val_acc, num = [0,0,0], [0,0,0]\n",
    "\n",
    "# for i, batch in tqdm(enumerate(model.val_dataloader()), total=len(model.val_dataset) // model.hparams.batch_size):\n",
    "for i, batch in tqdm(enumerate(val_dataloader), total=len(val_dataset) // model.hparams.batch_size):\n",
    "    inputs = model.tokenizer.batch_encode_plus(batch[0], pad_to_max_length=True, return_tensors='pt').to(device)\n",
    "    input_ids = inputs['input_ids']\n",
    "    mask = inputs['attention_mask']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "    labels = batch[1].to(device)\n",
    "    # rationale_ids = batch[2].to(device)\n",
    "    \n",
    "    logits = model.forward(input_ids, mask, token_type_ids)[0]\n",
    "    # logits = model.forward(input_ids, mask, token_type_ids, rationale_ids=rationale_ids)[0]\n",
    "\n",
    "    for logit, label in zip(logits.argmax(-1), labels):\n",
    "        val_acc[label] += (logit == label).int()\n",
    "        num[label] += 1\n",
    "\n",
    "print('entailment acc:', (val_acc[0] / num[0]), num[0]) # 'entailment': 0, 'neutral': 1, 'contradiction': 2\n",
    "print('neutral acc:', (val_acc[1] / num[1]), num[1])\n",
    "print('contradiction acc:', (val_acc[2] / num[2]), num[2])\n",
    "print('all acc:', (sum(val_acc) / sum(num)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esnli",
   "language": "python",
   "name": "esnli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
