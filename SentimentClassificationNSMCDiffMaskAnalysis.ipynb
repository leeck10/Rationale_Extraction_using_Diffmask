{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm\n",
    "\n",
    "from diffmask.models.sentiment_classification_sst_diffmask import (\n",
    "    BertSentimentClassificationSSTDiffMask,\n",
    "    RecurrentSentimentClassificationSSTDiffMask,\n",
    "    PerSampleDiffMaskRecurrentSentimentClassificationSSTDiffMask,\n",
    "    PerSampleREINFORCERecurrentSentimentClassificationSSTDiffMask,\n",
    ")\n",
    "from diffmask.utils.plot import plot_sst_attributions\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--gpu\", type=str, default=\"0\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"./datasets/KorBERT\")\n",
    "    parser.add_argument(\"--train_filename\", type=str, default=\"./datasets/nsmc/ratings_train.txt\")\n",
    "    parser.add_argument(\"--val_filename\", type=str, default=\"./datasets/nsmc/ratings_test.txt\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--gate_bias\", action=\"store_true\")\n",
    "    parser.add_argument(\"--seed\", type=float, default=0)\n",
    "    parser.add_argument(\"--architecture\", type=str, default=\"bert\", choices=[\"gru\", \"bert\"])\n",
    "    parser.add_argument(\n",
    "        \"--model_path\",\n",
    "        type=str,\n",
    "        default=\"outputs/models.ckpt\",\n",
    "#         or\n",
    "#         default=\"models/sst-diffmask-input.ckpt\",\n",
    "    )\n",
    "    parser.add_argument(\"--num_labels\", type=int, default=2)\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"nsmc\", choices=[\"nsmc\", \"kornli\"])\n",
    "\n",
    "    hparams, _ = parser.parse_known_args()\n",
    "\n",
    "    torch.manual_seed(hparams.seed)\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = hparams.gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "if hparams.architecture == \"bert\":\n",
    "    model = BertSentimentClassificationSSTDiffMask.load_from_checkpoint(hparams.model_path).to(device)\n",
    "elif hparams.architecture == \"gru\":\n",
    "    if \"per_sample-diffmask\" in hparams.model_path:\n",
    "        model = PerSampleDiffMaskRecurrentSentimentClassificationSSTDiffMask.load_from_checkpoint(\n",
    "            hparams.model_path\n",
    "        ).to(device)\n",
    "    elif \"per_sample-reinforce\" in hparams.model_path:\n",
    "        model = PerSampleREINFORCERecurrentSentimentClassificationSSTDiffMask.load_from_checkpoint(\n",
    "            hparams.model_path\n",
    "        ).to(device)\n",
    "    else:\n",
    "        model = RecurrentSentimentClassificationSSTDiffMask.load_from_checkpoint(\n",
    "            hparams.model_path\n",
    "        ).to(device)\n",
    "\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and plotting DiffMask attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.prepare_data()\n",
    "\n",
    "save_path = ''\n",
    "\n",
    "with open(save_path, 'w') as f:\n",
    "    for i, batch in tqdm(enumerate(model.val_dataloader()), total=len(model.val_dataset) // model.hparams.batch_size):\n",
    "        inputs = model.tokenizer.batch_encode_plus(batch[0], pad_to_max_length=True, return_tensors='pt').to(device)\n",
    "        input_ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        labels = batch[1]\n",
    "\n",
    "        attributions = model.forward_explainer(\n",
    "            input_ids, mask, token_type_ids, attribution=True\n",
    "        ).exp()\n",
    "\n",
    "        for idx in range(len(batch[0])):\n",
    "            source = model.tokenizer.tokenize(batch[0][idx])\n",
    "            tokens = [\"[CLS]\"] + source + [\"[SEP]\"]\n",
    "            rationale, rationale_idx = [], []\n",
    "    \n",
    "            gate = attributions[idx, :len(tokens)].cpu() >= 0.5\n",
    "            score = list(map(lambda x: x >= 7, (gate.int()).sum(1)))\n",
    "            for j, s in enumerate(score):\n",
    "                if s and tokens[j] != '[CLS]' and tokens[j] != '[SEP]':\n",
    "                    rationale.append(tokens[j])\n",
    "\n",
    "            f.write(str(labels[idx].tolist()) + '\\t' + ' '.join(rationale) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = \"정말 최고의 영화. 어떤 영화 보다도 멋지고 아름답다\"\n",
    "\n",
    "source = model.tokenizer.tokenize(source)\n",
    "tokens = [\"[CLS]\"] + source + [\"[SEP]\"]\n",
    "for i in range(len(tokens)):\n",
    "    tokens[i] = ' ' + tokens[i]\n",
    "    \n",
    "inputs_dict = {\n",
    "    k: v.to(device)\n",
    "    for k, v in model.tokenizer.encode_plus(\n",
    "        source,\n",
    "        pad_to_max_length=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).items()\n",
    "}\n",
    "inputs_dict[\"mask\"] = inputs_dict[\"attention_mask\"]\n",
    "del inputs_dict[\"attention_mask\"]\n",
    "\n",
    "attributions = model.forward_explainer(\n",
    "    **inputs_dict, attribution=True\n",
    ").exp()[0,:len(tokens)].cpu() >= 0.5\n",
    "\n",
    "attributions = attributions.int()\n",
    "plot_sst_attributions(attributions, tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffmask",
   "language": "python",
   "name": "diffmask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
